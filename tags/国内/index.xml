<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>国内 on NJU AI 通识课</title><link>https://nil-zhuang.github.io/NJU-AI-Course/tags/%E5%9B%BD%E5%86%85/</link><description>Recent content in 国内 on NJU AI 通识课</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 28 Aug 2024 15:16:39 +0800</lastBuildDate><atom:link href="https://nil-zhuang.github.io/NJU-AI-Course/tags/%E5%9B%BD%E5%86%85/index.xml" rel="self" type="application/rss+xml"/><item><title>Kimi.ai</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/kimi_ai/</link><pubDate>Wed, 28 Aug 2024 15:16:39 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/kimi_ai/</guid><description>&lt;h4 id="kimi-功能">Kimi 功能：&lt;/h4>
&lt;p>&lt;img src="https://picx.zhimg.com/v2-93823535f337e397c8251039f5c0458d.webp" alt="img">&lt;/p>
&lt;ol>
&lt;li>长文总结和生成功能：能够高效地提炼大量信息，支持最多50个文件，接受pdf、doc、xlsx、PPT、txt、图片等多种格式；&lt;/li>
&lt;li>联网搜索功能：帮助用户快速获取所需信息，提升了工作效率；&lt;/li>
&lt;li>数据处理功能：能够处理和分析复杂数据，为企业决策提供了有力支持；&lt;/li>
&lt;li>编写代码功能：使得Kimi能够辅助开发者进行编程工作，提高了开发效率&lt;/li>
&lt;li>用户交互功能：使得Kimi能够与用户进行自然流畅的对话，提升了用户体验；&lt;/li>
&lt;li>翻译功能：帮助用户跨越语言障碍，实现全球范围内的信息交流。&lt;/li>
&lt;/ol></description></item><item><title>剪映</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/capcut/</link><pubDate>Wed, 28 Aug 2024 15:15:23 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/capcut/</guid><description>&lt;p>字幕识别，智能定位素材，音频美化，声音克隆，智能打光，画面超分，镜头跟踪，智能运镜&lt;/p></description></item><item><title>可灵 AI</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/klingai/</link><pubDate>Wed, 28 Aug 2024 15:15:12 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/klingai/</guid><description>&lt;p>可灵大模型（Kling）是由快手大模型团队自研打造的视频生成大模型，具备强大的视频生成能力，让用户可以轻松高效地完成艺术视频创作&lt;/p>
&lt;ul>
&lt;li>大幅度的合理运动：可灵采用3D时空联合注意力机制，能够更好地建模复杂时空运动，生成较大幅度运动的视频内容，同时能够符合运动规律。&lt;/li>
&lt;li>长达2分钟的视频生成：得益于高效的训练基础设施、极致的推理优化和可扩展的基础架构，可灵大模型能够生成长达2分钟的视频，且帧率达到30fps。&lt;/li>
&lt;li>模拟物理世界特性：基于自研模型架构及Scaling Law激发出的强大建模能力，可灵能够模拟真实世界的物理特性，生成符合物理规律的视频。&lt;/li>
&lt;li>强大的概念组合能力：基于对文本-视频语义的深刻理解和 Diffusion Transformer 架构的强大能力，可灵能够将用户丰富的想象力转化为具体的画面，虚构真实世界中不会出现的的场景&lt;/li>
&lt;li>电影级的画面生成：基于自研3D VAE，可灵能够生成1080p分辨率的电影级视频，无论是浩瀚壮阔的宏大场景，还是细腻入微的特写镜头，都能够生动呈现。&lt;/li>
&lt;li>支持自由的输出视频宽高比：可灵采用了可变分辨率的训练策略，在推理过程中可以做到同样的内容输出多种多样的视频宽高比，满足更丰富场景中的视频素材使用需求。&lt;/li>
&lt;/ul></description></item><item><title>Cool Papers</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/coolpapers/</link><pubDate>Wed, 28 Aug 2024 15:13:47 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/coolpapers/</guid><description>&lt;p>@Copyright 苏剑林 科学FM &lt;a href="https://kexue.fm/archives/10088">https://kexue.fm/archives/10088&lt;/a>&lt;/p>
&lt;h2 id="写在开头">写在开头&lt;/h2>
&lt;p>一直以来，笔者都有日刷Arxiv的习惯，以求尽可能跟上领域内最新成果，并告诫自己“不进则退”。之前也有不少读者问我是怎么刷Arxiv的、有什么辅助工具等，但事实上，在很长的时间里，笔者都是直接刷Arxiv官网，并且没有用任何算法过滤，都是自己一篇篇过的。这个过程很枯燥，但并非不能接受，之所以不用算法初筛，主要还是担心算法漏召，毕竟“刷”就是为了追新，一旦算法漏召就“错失先机”了。&lt;/p>
&lt;p>自从Kimi Chat发布后，笔者就一直计划着写一个辅助网站结合Kimi来加速刷论文的过程。最近几个星期稍微闲了一点，于是在GPT4、Kimi的帮助下，初步写成了这个网站，并且经过几天的测试和优化后，已经逐步趋于稳定，于是正式邀请读者试用。&lt;/p>
&lt;p>Cool Papers：https://papers.cool&lt;/p>
&lt;h2 id="写在中间">写在中间&lt;/h2>
&lt;p>正如“Cool Papers”这个名字所述，该网站希望让刷论文变成一种非常“酷”的沉浸式体验。当然，目前的实现还是比较简陋，“酷”主要体现在通过Kimi回答了几个论文的FAQ，这可以让我们更加准确、高效地了解论文的主要内容（相比只看标题、摘要），从而判断是否是需要精读的论文。&lt;/p>
&lt;p>特别要指出的是：&lt;/p>
&lt;p>1、这是一个“刷”论文的网站，不是“读”论文的网站，“刷”的意思是“筛”、“过滤”，“刷”的目的是找出需要精读的论文，而不是代替精读；
2、目前只支持Arxiv作为论文源，实时同步Arxiv的最新一天的论文列表，所以刷Cool Papers基本上能等价于刷Arxiv，未来可能会接入其他论文源，比如OpenReview，这个看后面的使用情况和反馈再做计划；
3、因为定位为“刷”，所以“贵在坚持，过时不候”，因此目前只支持显示最新一天的论文，暂时不支持历史回溯，当然这个也可以根据读者后面的反馈需求再做改动；
4、FAQ基于Kimi Chat，请大家感恩并珍惜，事实上根据标题和摘要基本上也能筛掉不少论文了，Kimi FAQ的存在是为了对不确定的论文做更精准的判断，所以不要随意点“[Kimi]”；
5、点击“[PDF]”可以预览论文内容（仅限PC浏览器，手机浏览器会触发下载），但这个是依赖于自己的网页去访问Arxiv，所以如果迟迟不出来，可能是自身网络问题；
6、点击“[Copy]”会将论文的基本信息（标题、摘要、链接等）复制到剪切板中，可以在其他地方粘贴，从而分享论文；
7、论文列表默认保持Arxiv的发布顺序，如果加上“-sorted-by-stars”，则按照所有用户的点击情况计算的stars进行排序；
8、论文更新：论文的更新是直接同步Arxiv官网的，正常延迟不超过10分钟，Arxiv更新时间一般在工作日早上十点左右（北京时间），但波动可能有几个小时，并且周六日和美国的一些节假日都是不更新的，如果发现网站论文没有更新，可以到Arxiv官方上确认一下更新情况。&lt;/p>
&lt;h2 id="关于kimi-faq的进一步说明">关于Kimi FAQ的进一步说明：&lt;/h2>
&lt;p>1、点击每篇论文对应的“[Kimi]”后，会进入排队；
2、如果排队人数比较多，会显示“Pending:xxx”的结果，“xxx”是排队数，该数字会自动更新；
3、排队完成后会显示“Loading:xxx%”，随后流式输出FAQ内容；
4、排队和生成的过程不需要保持页面打开，即便关闭页面也会在后台保持排队和生成，并且重新打开页面并点击同一“[Kimi]”时会恢复原来的进度；
5、如果你点击“[Kimi]”后发现瞬间就输出完了FAQ内容，那就意味着这篇论文已经被其他读者读过，FAQ被缓存了下来；
6、因为有排队机制，所以随意点“[Kimi]”倒是不会让网站有太大压力，但会让别人的等待时间过长，这是一个不友善的行为。&lt;/p>
&lt;h2 id="写在结尾">写在结尾&lt;/h2>
&lt;p>最后，欢迎大家的意见和建议，也欢迎大家继续提需求。很明显，目前的Cool Papers还非常粗糙，远没有想象中那么“酷”，并且用Kimi做FAQ也仅仅是Kimi与论文结合的一个非常基本的方案，Kimi的超长Context应该还有非常大的想象空间。所以非常期待大家发挥想象力，找到Kimi与刷论文的更完美的结合方式。&lt;/p></description></item><item><title>火山翻译</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/volcengine_translate/</link><pubDate>Wed, 28 Aug 2024 15:13:30 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/volcengine_translate/</guid><description>&lt;h2 id="在火山让翻译更简单">在火山，让翻译更简单&lt;/h2>
&lt;p>依托百亿级数据积累和行业前沿算法，火山翻译向企业客户提供翻译 API、火山同传等产品服务，适用于直播同传、海外内容翻译等场景。同时，我们也在浏览器插件、在线翻译器等产品上向个人用户提供丰富、便捷的翻译功能。&lt;/p>
&lt;h2 id="丰富的产品和服务能力">丰富的产品和服务能力&lt;/h2>
&lt;p>从个人到企业，从文本翻译到音视频翻译，从标准API到定制化服务，各类型能力可满足不同场景需要&lt;/p>
&lt;h2 id="前沿的算法能力">前沿的算法能力&lt;/h2>
&lt;p>由字节跳动 AI Lab（人工智能实验室）自主研发，屡次斩获机器翻译大赛重磅奖项、学术研究成果国际知名，保证了先进的翻译质量和服务优化的长期投入&lt;/p>
&lt;h2 id="广泛的行业应用场景">广泛的行业应用场景&lt;/h2>
&lt;p>各行各业个人用户和企业客户的共同选择，为直播、游戏、电商等行业提供完善的翻译解决方案&lt;/p></description></item><item><title>通义千问</title><link>https://nil-zhuang.github.io/NJU-AI-Course/posts/qwen/</link><pubDate>Sun, 25 Aug 2024 12:08:58 +0800</pubDate><guid>https://nil-zhuang.github.io/NJU-AI-Course/posts/qwen/</guid><description>&lt;p>阿里巴巴的&amp;quot;通义千问&amp;quot;是阿里云自主研发的大语言模型，于2023年4月首次问世，致力于基础模型的技术研发，并不断升级迭代。最新版本2.5在理解能力、逻辑推理、指令遵循和代码能力等方面均有显著提升，尤其在中文能力方面持续领先业界。此外，通义还发布了1100亿参数的开源模型Qwen1.5-110B，在多个基准测评中超越了Meta的Llama-3-70B模型，登顶HuggingFace开源大模型排行榜。&lt;/p>
&lt;p>通义千问在多模态模型和专有能力模型方面也具有业界顶尖影响力，如视觉理解模型Qwen-VL-Max和代码大模型CodeQwen1.5-7B均在各自领域取得优异成绩。通义千问已广泛应用于文生图、智能编码、文档解析、音视频理解等多个领域，企业客户和开发者可以通过API调用或模型下载等方式接入通义，个人用户也可免费使用。&lt;/p>
&lt;p>阿里云坚定地走开源路线，推动大模型开源，让更多开发者和中小企业能够使用和迭代大模型，加速了大模型的应用落地进程。通义推出了参数规模从5亿到1100亿不等的多款大语言模型，满足不同场景用户的需求。&lt;/p>
&lt;p>2024年5月24日，通义千问2.5正式发布，相比上一版本在多个方面有显著提升。同时，通义还推出了多模态AI生成能力，并与小米、微博、众安保险等企业达成合作，将大模型应用于社交媒体、保险、游戏等领域。&lt;/p></description></item></channel></rss>