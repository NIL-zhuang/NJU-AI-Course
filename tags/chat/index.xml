<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chat on NJU AI 通识课</title><link>https://example.org/tags/chat/</link><description>Recent content in Chat on NJU AI 通识课</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 28 Aug 2024 15:16:39 +0800</lastBuildDate><atom:link href="https://example.org/tags/chat/index.xml" rel="self" type="application/rss+xml"/><item><title>Kimi.ai</title><link>https://example.org/posts/kimi_ai/</link><pubDate>Wed, 28 Aug 2024 15:16:39 +0800</pubDate><guid>https://example.org/posts/kimi_ai/</guid><description>Kimi 功能： 长文总结和生成功能：能够高效地提炼大量信息，支持最多50个文件，接受pdf、doc、xlsx、PPT、txt、图片等多种格式； 联网搜索功能：帮助用户快速获取所需信息，提升了工作效率； 数据处理功能：能够处理和分析复杂数据，为企业决策提供了有力支持； 编写代码功能：使得Kimi能够辅助开发者进行编程工作，提高了开发效率 用户交互功能：使得Kimi能够与用户进行自然流畅的对话，提升了用户体验； 翻译功能：帮助用户跨越语言障碍，实现全球范围内的信息交流。</description></item><item><title>ChatGPT</title><link>https://example.org/posts/chatgpt/</link><pubDate>Sun, 25 Aug 2024 12:08:58 +0800</pubDate><guid>https://example.org/posts/chatgpt/</guid><description>我们已经训练了一个名为ChatGPT的模型，它以对话的方式进行交互。对话格式使ChatGPT有可能回答后续问题，承认其错误，挑战不正确的前提，并拒绝不适当的请求。ChatGPT是InstructGPT的兄弟模型，它被训练为遵循提示中的指令并提供详细的响应。我们很高兴地介绍ChatGPT以获得用户的反馈并了解其优缺点。在研究预览期间，ChatGPT的使用是免费的。立即在 https://chatgpt.com/ 尝试。
Methods 我们使用来自人类反馈的强化学习（RLHF）训练这个模型，使用与InstructGPT相同的方法，但数据采集设置略有不同。我们使用监督微调训练了一个初始模型：人类人工智能培训师提供对话，他们在对话中扮演双方——用户和人工智能助手。我们让培训师访问模型编写的建议，以帮助他们编写响应。我们将这个新的对话数据集与InstructGPT数据集混合在一起，并将其转换为对话格式。为了创建强化学习的奖励模型，我们需要收集比较数据，其中包括两个或多个按质量排序的模型响应。
为了收集这些数据，我们采用了人工智能培训师与聊天机器人的对话。我们随机选择一条模型编写的消息，采样几个替代完成，并让人工智能培训师对它们进行排名。使用这些奖励模型，我们可以使用邻近策略优化来微调模型。
ChatGPT是从GPT-3.5系列的模型中微调的，该系列于2022年初完成了训练。您可以在此处了解有关3.5系列的更多信息（在新窗口中打开）。ChatGPT和GPT-3.5是在Azure AI超级计算基础架构上进行训练的。
Limitations ChatGPT有时会写出听起来合理但不正确或荒谬的答案。解决这个问题具有挑战性，因为：（1）在RL训练期间，目前没有事实来源；（2）训练模型更加谨慎会导致它拒绝它能正确回答的问题；（3）监督训练会误导模型，因为理想的答案取决于模型知道什么（在新窗口中打开），而不是人类演示者知道什么。
ChatGPT对输入措辞的调整或多次尝试相同的提示很敏感。例如，给定一个问题的措辞，模型可以声称不知道答案，但只要稍微改变一下措辞，就可以正确回答。
该模型经常过于冗长，过度使用某些短语，例如重申它是由OpenAI训练的语言模型。这些问题源于训练数据中的偏见（培训师更喜欢看起来更全面的更长答案）和众所周知的过度优化问题。
理想情况下，当用户提供模棱两可的查询时，模型会提出澄清问题。相反，我们当前的模型通常会猜测用户的意图。虽然我们已经努力使模型拒绝不适当的请求，但它有时会对有害的指令做出反应或表现出有偏见的行为。
我们正在使用审核API来警告或阻止某些类型的不安全内容，但我们预计它目前会有一些假阴性和阳性。我们渴望收集用户反馈，以帮助我们正在进行的工作来改进这个系统。
迭代部署 今天发布的ChatGPT研究版本是OpenAI迭代部署越来越安全和有用的人工智能系统的最新一步。GPT-3和法典等早期模型部署的许多经验教训为本版本提供了安全缓解措施，包括通过使用人类反馈强化学习（RLHF）大幅减少有害和不真实的输出。</description></item><item><title>Claude</title><link>https://example.org/posts/claude/</link><pubDate>Sun, 25 Aug 2024 12:08:58 +0800</pubDate><guid>https://example.org/posts/claude/</guid><description>Claude 高级推理: Claude可以执行超越简单模式识别或文本生成的复杂认知任务 视觉分析: 转录和分析几乎任何静态图像，从手写笔记和图表到照片 代码生成: 开始使用超文本标记语言和CSS创建网站，将图像转换为结构化JSON数据，或调试复杂的代码库 多语言处理: 在各种语言之间实时翻译、练习语法或创建多语言内容 Claude系列模型适合任何任务，提供速度和性能的最佳组合。
Haiku: 我们最快的模型可以执行轻量级操作，速度领先行业。 Sonnet: 我们的性能和速度的最佳组合，可实现高效、高吞吐量的任务。 Opus: 我们性能最高的模型，可以处理复杂的分析、具有许多步骤的较长任务以及高阶数学和编码任务。</description></item><item><title>通义千问</title><link>https://example.org/posts/qwen/</link><pubDate>Sun, 25 Aug 2024 12:08:58 +0800</pubDate><guid>https://example.org/posts/qwen/</guid><description>阿里巴巴的&amp;quot;通义千问&amp;quot;是阿里云自主研发的大语言模型，于2023年4月首次问世，致力于基础模型的技术研发，并不断升级迭代。最新版本2.5在理解能力、逻辑推理、指令遵循和代码能力等方面均有显著提升，尤其在中文能力方面持续领先业界。此外，通义还发布了1100亿参数的开源模型Qwen1.5-110B，在多个基准测评中超越了Meta的Llama-3-70B模型，登顶HuggingFace开源大模型排行榜。
通义千问在多模态模型和专有能力模型方面也具有业界顶尖影响力，如视觉理解模型Qwen-VL-Max和代码大模型CodeQwen1.5-7B均在各自领域取得优异成绩。通义千问已广泛应用于文生图、智能编码、文档解析、音视频理解等多个领域，企业客户和开发者可以通过API调用或模型下载等方式接入通义，个人用户也可免费使用。
阿里云坚定地走开源路线，推动大模型开源，让更多开发者和中小企业能够使用和迭代大模型，加速了大模型的应用落地进程。通义推出了参数规模从5亿到1100亿不等的多款大语言模型，满足不同场景用户的需求。
2024年5月24日，通义千问2.5正式发布，相比上一版本在多个方面有显著提升。同时，通义还推出了多模态AI生成能力，并与小米、微博、众安保险等企业达成合作，将大模型应用于社交媒体、保险、游戏等领域。</description></item></channel></rss>